{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.24.5)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyMuPDFb==1.24.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pymupdf) (1.24.3)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.23.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (24.0)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading PyYAML-6.0.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (2024.4.16)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (2.32.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (4.66.2)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.23.0->transformers)\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (2024.2.2)\n",
      "Downloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.23.2-py3-none-any.whl (401 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.7/401.7 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.1-cp312-cp312-macosx_11_0_arm64.whl (165 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.6/165.6 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp312-cp312-macosx_11_0_arm64.whl (411 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.1/411.1 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp312-cp312-macosx_11_0_arm64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, pyyaml, fsspec, filelock, huggingface-hub, tokenizers, transformers\n",
      "\u001b[33m  WARNING: The script huggingface-cli is installed in '/Library/Frameworks/Python.framework/Versions/3.12/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script transformers-cli is installed in '/Library/Frameworks/Python.framework/Versions/3.12/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed filelock-3.14.0 fsspec-2024.5.0 huggingface-hub-0.23.2 pyyaml-6.0.1 safetensors-0.4.3 tokenizers-0.19.1 transformers-4.41.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymupdf transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import openai\n",
    "\n",
    "# Function to set the OpenAI API key\n",
    "def set_openai_api_key(api_key):\n",
    "    openai.api_key = api_key\n",
    "\n",
    "# Function to read the playbook PDF document\n",
    "def read_playbook_pdf(file_path):\n",
    "    document = fitz.open(file_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(document)):\n",
    "        page = document.load_page(page_num)\n",
    "        text += page.get_text(\"text\") + \"\\n\"  # Add newline to separate pages\n",
    "    return text\n",
    "\n",
    "# Function to chunk the document\n",
    "def chunk_document(text, max_chunk_size=2000):\n",
    "    paragraphs = text.split('\\n')\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    \n",
    "    for paragraph in paragraphs:\n",
    "        if len(current_chunk) + len(paragraph) + 1 > max_chunk_size:\n",
    "            chunks.append(current_chunk)\n",
    "            current_chunk = paragraph + \"\\n\"\n",
    "        else:\n",
    "            current_chunk += paragraph + \"\\n\"\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk)\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Function to simplify text using the GPT-4 model\n",
    "def simplify_text(text, prompt):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": text}\n",
    "        ],\n",
    "        max_tokens=2000,\n",
    "        temperature=0.5,\n",
    "        top_p=1.0,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0\n",
    "    )\n",
    "    return response.choices[0].message['content'].strip()\n",
    "\n",
    "# Function to simplify the playbook and save it as a PDF\n",
    "def simplify_playbook(file_path, output_path, api_key, prompt):\n",
    "    # Set the OpenAI API key\n",
    "    set_openai_api_key(api_key)\n",
    "    \n",
    "    # Read the playbook PDF document\n",
    "    playbook_text = read_playbook_pdf(file_path)\n",
    "    \n",
    "    # Chunk the document\n",
    "    chunks = chunk_document(playbook_text)\n",
    "    \n",
    "    # Simplify each chunk\n",
    "    simplified_chunks = [simplify_text(chunk, prompt) for chunk in chunks]\n",
    "    \n",
    "    # Combine the simplified chunks\n",
    "    simplified_text = \"\\n\".join(simplified_chunks)\n",
    "    \n",
    "    # Create a new PDF with the simplified text\n",
    "    simplified_pdf = fitz.open()\n",
    "    simplified_text_chunks = simplified_text.split('\\n')\n",
    "    \n",
    "    page = simplified_pdf.new_page()\n",
    "    y = 72  # Starting position for text on the page\n",
    "    \n",
    "    for chunk in simplified_text_chunks:\n",
    "        page.insert_text((72, y), chunk, fontsize=12, fontname=\"helv\")\n",
    "        y += 14  # Move down for the next line\n",
    "        if y > 800:  # Create a new page if the current one is full\n",
    "            page = simplified_pdf.new_page()\n",
    "            y = 72\n",
    "\n",
    "    # Save the simplified PDF\n",
    "    simplified_pdf.save(output_path)\n",
    "    print(f\"Simplified playbook saved to {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "api_key = \"\"\n",
    "prompt = \"You are a legal expert tasked with simplifying complex legal language. Please rewrite the following text in plain language while retaining all legal terms, obligations, and details. Ensure that it remains legally accurate and clear to someone without a legal background. Avoid legal jargon and make it concise. Preserve all critical information and context:\\n\\n\"\n",
    "simplify_playbook('playbook2.pdf', 'simplified_playbook3.pdf', api_key, prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from transformers import pipeline\n",
    "\n",
    "# Function to read the playbook PDF document\n",
    "def read_playbook_pdf(file_path):\n",
    "    document = fitz.open(file_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(document)):\n",
    "        page = document.load_page(page_num)\n",
    "        text += page.get_text(\"text\") + \"\\n\"  # Add newline to separate pages\n",
    "    return text\n",
    "\n",
    "# Function to chunk the document\n",
    "def chunk_document(text, max_chunk_size=512):\n",
    "    paragraphs = text.split('\\n')\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "\n",
    "    for paragraph in paragraphs:\n",
    "        if len(current_chunk) + len(paragraph) + 1 > max_chunk_size:\n",
    "            chunks.append(current_chunk)\n",
    "            current_chunk = paragraph + \"\\n\"\n",
    "        else:\n",
    "            current_chunk += paragraph + \"\\n\"\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Function to simplify text using a Hugging Face model\n",
    "def simplify_text(text, simplifier):\n",
    "    simplified_text = simplifier(text)[0]['generated_text']\n",
    "    return simplified_text\n",
    "\n",
    "# Function to simplify the playbook and save it as a PDF\n",
    "def simplify_playbook(file_path, output_path, simplifier):\n",
    "    # Read the playbook PDF document\n",
    "    playbook_text = read_playbook_pdf(file_path)\n",
    "\n",
    "    # Chunk the document\n",
    "    chunks = chunk_document(playbook_text)\n",
    "\n",
    "    # Simplify each chunk\n",
    "    simplified_chunks = [simplify_text(chunk, simplifier) for chunk in chunks]\n",
    "\n",
    "    # Combine the simplified chunks\n",
    "    simplified_text = \"\\n\".join(simplified_chunks)\n",
    "\n",
    "    # Create a new PDF with the simplified text\n",
    "    simplified_pdf = fitz.open()\n",
    "    simplified_text_chunks = simplified_text.split('\\n')\n",
    "\n",
    "    page = simplified_pdf.new_page()\n",
    "    y = 72  # Starting position for text on the page\n",
    "\n",
    "    for chunk in simplified_text_chunks:\n",
    "        page.insert_text((72, y), chunk, fontsize=12, fontname=\"helv\")\n",
    "        y += 14  # Move down for the next line\n",
    "        if y > 800:  # Create a new page if the current one is full\n",
    "            page = simplified_pdf.new_page()\n",
    "            y = 72\n",
    "\n",
    "    # Save the simplified PDF\n",
    "    simplified_pdf.save(output_path)\n",
    "    print(f\"Simplified playbook saved to {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "model_name = \"t5-base\"  # You can also use other models like \"facebook/bart-large-cnn\"\n",
    "simplifier = pipeline(\"text2text-generation\", model=\"muheng/finetuned-contract-legal\")\n",
    "\n",
    "\n",
    "simplify_playbook('/content/playbook2.pdf', 'simplified_playbook.pdf', simplifier)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
